{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training\n",
    "\n",
    "If you try searching for ways to train SVMs without using solvers or existing packages you may end up in the same position as me. The math behind SVMs can be expressed fairly simply, optimization is a different ball game.\n",
    "\n",
    "$min_{w,b} \\: \\frac{1}{2}w^Tw + C\\sum^{N}_{i}{\\xi_i}$ \n",
    "\n",
    "$st. \\: y_i(w^Tx_i + b) \\geq 1 - \\xi_i$\n",
    "\n",
    "and\n",
    "\n",
    "$\\xi_i \\geq 0$\n",
    "\n",
    "Reordering the constraint we get\n",
    "\n",
    "$1 - y_i(w^Tx_i + b) \\leq \\xi_i$\n",
    "\n",
    "Meaning that $\\xi_i$ is $1 - y_i(w^Tx_i + b)$ if $1 - y_i(w^Tx_i + b) \\geq 0$ and $0$ if otherwise, written more succinctly\n",
    "\n",
    "$max(1 - y_i(w^Tx_i + b), 0)$\n",
    "\n",
    "Thus, we get the sometimes (partially) differential objective\n",
    "\n",
    "$min_{w,b} \\: \\frac{1}{2}w^Tw + C\\sum^{N}_{i}{max(1 - y_i(w^Tx_i + b), 0)}$ \n",
    "\n",
    "Where \n",
    "\n",
    "$min_{w,b} \\: \\sum^{N}_{i}{max(1 - y_i(w^Tx_i + b), 0)}$ \n",
    "\n",
    "is called hinge loss and\n",
    "\n",
    "$min_{w,b} \\: \\frac{1}{2}w^Tw$\n",
    "\n",
    "is L2 regularization. Taking the derivative of the max function gives us\n",
    "\n",
    "$\\frac{\\partial}{\\partial w} (max(1 - y_i(w^Tx_i + b), 0)) = \\left\\{ \\begin{array}{ll} 0 \\quad max(1 - y_i(w^Tx_i + b), 0) = 0 \\\\ y_ix_i \\quad \\text{else} \\end{array} \\right.$\n",
    "\n",
    "and \n",
    "\n",
    "$\\frac{\\partial}{\\partial b} (max(1 - y_i(w^Tx_i + b), 0)) = \\left\\{ \\begin{array}{ll} 0 \\quad max(1 - y_i(w^Tx_i + b), 0) = 0 \\\\ y_i \\quad \\text{else} \\end{array} \\right.$\n",
    "\n",
    "So our stochastic gradient update is\n",
    "\n",
    "$w \\leftarrow w - \\eta * (w + C \\frac{\\partial}{\\partial w} (max(1 - y_i(w^Tx_i + b), 0)))$\n",
    "\n",
    "$b \\leftarrow b - \\eta * \\frac{\\partial}{\\partial b} (max(1 - y_i(w^Tx_i + b), 0))$\n",
    "\n",
    "We can try our hand made solution and compare it to quadratic programming solver that explicitly attempts the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0rc1 (main, Aug  8 2022, 11:30:54) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
